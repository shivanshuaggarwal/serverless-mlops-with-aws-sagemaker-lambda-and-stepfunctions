{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run and end-to-end ML pipeline using AWS SageMaker and Lambda\n",
    "\n",
    "**This sample is provided for demonstration purposes, make sure to conduct appropriate testing if derivating this code for your own use-cases!**\n",
    "\n",
    "### Step 0: Get Admin Setup Results\n",
    "Bucket names, codecommit repo, docker image, IAM roles, ...\n",
    "\n",
    "In order to keep things orginized, we will save our `Source Code` (data processing, model training/serving scripts), `datasets`, as well as our trained `model(s) binaries` and their `test-performance metrics` all on S3, **versioned with respect to the date/time of each update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import zipfile\n",
    "import json\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.s3 import S3Uploader\n",
    "session = boto3.session.Session()\n",
    "\n",
    "# Grab admin resources (S3 Bucket name, IAM Roles and Docker Image for Training)\n",
    "with open('admin_setup.txt', 'r') as filehandle:\n",
    "    admin_setup = json.load(filehandle)\n",
    "\n",
    "# MLOps Hygiene\n",
    "WORKFLOW_NAME = \"my-project-2\"\n",
    "BUCKET = admin_setup[\"project_bucket\"]\n",
    "SOURCE_DATA = admin_setup[\"raw_data_path\"]\n",
    "BRANCH = \"master\"\n",
    "REPO = admin_setup[\"repo_name\"]\n",
    "\n",
    "REGION = session.region_name\n",
    "TRAINING_IMAGE = admin_setup[\"docker_image\"]\n",
    "WORKFLOW_EXECUTION_ROLE = admin_setup[\"workflow_execution_role\"]\n",
    "WORKFLOW_DATE_TIME = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "TRAINING_JOB_NAME = \"{}-{}\".format(WORKFLOW_NAME, WORKFLOW_DATE_TIME)\n",
    "SOURCE_CODE_PREFIX = \"{}/{}\".format(WORKFLOW_DATE_TIME, \"source-code\")\n",
    "\n",
    "my_workflow_input = {\n",
    "    #ADMIN\n",
    "    \"REGION\":REGION,\n",
    "    \"ROLE_ARN\":WORKFLOW_EXECUTION_ROLE,\n",
    "    \"BUCKET\":BUCKET,\n",
    "    \"WORKFLOW_NAME\":WORKFLOW_NAME,\n",
    "    \"WORKFLOW_DATE_TIME\":WORKFLOW_DATE_TIME,\n",
    "    \"DATA_SOURCE\":SOURCE_DATA,\n",
    "\n",
    "    # CodeCommit\n",
    "    \"REPO\":REPO,\n",
    "    \"BRANCH\":BRANCH,\n",
    "    \"DATA_PROCESSING_DIR\": \"sagemaker-processing-src\",\n",
    "    \"ML_DIR\": \"sagemaker-train-serve-src\",\n",
    "    \n",
    "    # SM Processing\n",
    "    \"PROCESSING_SCRIPT\":\"processing.py\",\n",
    "    \"PROCESSING_IMAGE\":TRAINING_IMAGE,\n",
    "    \"PROCESSING_INSTANCE_TYPE\":\"ml.c5.xlarge\",\n",
    "    \"PROCESSING_INSTANCE_COUNT\":1,\n",
    "    \"PROCESSING_VOLUME_SIZE_GB\":10,\n",
    "    \n",
    "    # SM TRAINING\n",
    "    \"TRAINING_SCRIPT\":\"train.py\",\n",
    "    \"TRAINING_IMAGE\":TRAINING_IMAGE,\n",
    "    \"TRAINING_INSTANCE_TYPE\":\"ml.c5.xlarge\",\n",
    "    \"TRAINING_INSTANCE_COUNT\":1,\n",
    "    \"TRAINING_VOLUME_SIZE_GB\":10,\n",
    "    \n",
    "    # SM SERVING\n",
    "    \"SERVING_SCRIPT\":\"serve.py\",\n",
    "    \"SERVING_IMAGE\":TRAINING_IMAGE,\n",
    "    \"SERVING_INSTANCE_TYPE\":\"ml.c5.xlarge\",\n",
    "    \"SERVING_INSTANCE_COUNT\":1,\n",
    "    \"SERVING_VOLUME_SIZE_GB\":10,\n",
    "}\n",
    "\n",
    "# The following method will be used throughout this notebook to create Lambda functions without going to the console\n",
    "session = sagemaker.Session()\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "def create_lambda_function(zip_name, lambda_source_code, function_name, description):\n",
    "    zf = zipfile.ZipFile(zip_name, mode='w')\n",
    "    zf.write(lambda_source_code, arcname=lambda_source_code.split('/')[-1])\n",
    "    zf.close()\n",
    "\n",
    "    S3Uploader.upload(local_path=zip_name, \n",
    "                      desired_s3_uri=\"s3://{}/{}\".format(BUCKET, SOURCE_CODE_PREFIX),\n",
    "                      session=session\n",
    "                     )\n",
    "\n",
    "    response = lambda_client.create_function(\n",
    "        FunctionName=function_name,\n",
    "        Runtime='python3.6',\n",
    "        Role=WORKFLOW_EXECUTION_ROLE,\n",
    "        Handler=zip_name.split('.')[0]+'.lambda_handler',\n",
    "        Code={\n",
    "            'S3Bucket': BUCKET,\n",
    "            'S3Key': '{}/{}'.format(SOURCE_CODE_PREFIX, zip_name)\n",
    "        },\n",
    "        Description=description,\n",
    "        Timeout=180,\n",
    "        MemorySize=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Move Code from CodeCommit to S3\n",
    "The first step in training a model on sagemaker is to copy our source code to S3. This step is automatically done for you when you use the SageMaker SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmimetypes\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtarfile\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mlambda_handler\u001b[39;49;00m(event, context):\r\n",
      "    \u001b[33m\"\"\" Pulls AWS Glue and SageMaker source code from CodeCommit and writes it to S3.\u001b[39;49;00m\r\n",
      "\u001b[33m    This funciton creates a tarball of the SageMaker scripts before sending to S3 since\u001b[39;49;00m\r\n",
      "\u001b[33m    SageMaker training jobs expect code to be in a tarball on S3.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# target bucket\u001b[39;49;00m\r\n",
      "    bucket = boto3.resource(\u001b[33m'\u001b[39;49;00m\u001b[33ms3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).Bucket(event[\u001b[33m'\u001b[39;49;00m\u001b[33mBUCKET\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    output_prefix = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(event[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORKFLOW_DATE_TIME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33msource-code\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# source codecommit\u001b[39;49;00m\r\n",
      "    codecommit = boto3.client(\u001b[33m'\u001b[39;49;00m\u001b[33mcodecommit\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, region_name=event[\u001b[33m'\u001b[39;49;00m\u001b[33mREGION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    repository_name = event[\u001b[33m'\u001b[39;49;00m\u001b[33mREPO\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    branch = event[\u001b[33m'\u001b[39;49;00m\u001b[33mBRANCH\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    ml_dir = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mML_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "    data_processing_dir = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mDATA_PROCESSING_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "\r\n",
      "    \u001b[37m# First create a tar ball with sagemaker scripts to S3 with name source.dir.tar.gz\u001b[39;49;00m\r\n",
      "    buf = io.BytesIO()\r\n",
      "    \u001b[34mwith\u001b[39;49;00m tarfile.open(\u001b[33m'\u001b[39;49;00m\u001b[33msourcedir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, mode=\u001b[33m\"\u001b[39;49;00m\u001b[33mw:gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, fileobj=buf) \u001b[34mas\u001b[39;49;00m tar:\r\n",
      "        \u001b[37m# Reads each file in the branch and uploads it to the s3 bucket\u001b[39;49;00m\r\n",
      "        \u001b[34mfor\u001b[39;49;00m blob \u001b[35min\u001b[39;49;00m get_blob_list(codecommit, repository_name, branch, ml_dir):\r\n",
      "            path = blob[\u001b[33m'\u001b[39;49;00m\u001b[33mpath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "            blobId = blob[\u001b[33m'\u001b[39;49;00m\u001b[33mblobId\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "            content = (codecommit.get_blob(repositoryName=repository_name, blobId=blobId))[\u001b[33m'\u001b[39;49;00m\u001b[33mcontent\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "            tarinfo = tarfile.TarInfo(path)\r\n",
      "            tarinfo.size = \u001b[36mlen\u001b[39;49;00m(content)\r\n",
      "            tar.addfile(tarinfo, io.BytesIO(content))\r\n",
      "    \u001b[37m# close tar file\u001b[39;49;00m\r\n",
      "    tarobject = buf.getvalue()\r\n",
      "    \u001b[37m# put tar ball in s3\u001b[39;49;00m\r\n",
      "    s3BucketKey = \u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(output_prefix, \u001b[33m'\u001b[39;49;00m\u001b[33msourcedir.tar.gz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    bucket.put_object(Body=(tarobject), Key=s3BucketKey)\r\n",
      "\r\n",
      "    \r\n",
      "    \u001b[37m# Sagemaker Processing.\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m blob \u001b[35min\u001b[39;49;00m get_blob_list(codecommit, repository_name, branch, data_processing_dir):\r\n",
      "        path = blob[\u001b[33m'\u001b[39;49;00m\u001b[33mpath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "        blobId=blob[\u001b[33m'\u001b[39;49;00m\u001b[33mblobId\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "        content = (codecommit.get_blob(repositoryName=repository_name, blobId=blobId))[\u001b[33m'\u001b[39;49;00m\u001b[33mcontent\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "        s3BucketKey = \u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(output_prefix, path)\r\n",
      "        bucket.put_object(Body=(content), Key=s3BucketKey)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mSUCCESS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)            \r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_blob_list\u001b[39;49;00m(codecommit, repository, branch, path):\r\n",
      "    \u001b[33m\"\"\" Returns a list of a all files in a CodeCommit branch\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    response = codecommit.get_differences(\r\n",
      "            repositoryName=repository,\r\n",
      "            afterCommitSpecifier=branch,\r\n",
      "            afterPath=path\r\n",
      "            )\r\n",
      "\r\n",
      "    blob_list = [difference[\u001b[33m'\u001b[39;49;00m\u001b[33mafterBlob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] \u001b[34mfor\u001b[39;49;00m difference \u001b[35min\u001b[39;49;00m response[\u001b[33m'\u001b[39;49;00m\u001b[33mdifferences\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\r\n",
      "    \u001b[34mwhile\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mnextToken\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m response:\r\n",
      "        response = codecommit.get_differences(\r\n",
      "                repositoryName=repository,\r\n",
      "                afterCommitSpecifier=branch,\r\n",
      "                nextToken=response[\u001b[33m'\u001b[39;49;00m\u001b[33mnextToken\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "                )\r\n",
      "        blob_list += [difference[\u001b[33m'\u001b[39;49;00m\u001b[33mafterBlob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] \u001b[34mfor\u001b[39;49;00m difference \u001b[35min\u001b[39;49;00m response[\u001b[33m'\u001b[39;49;00m\u001b[33mdifferences\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m blob_list    \r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./workflow-orchestration-src/codecommit_to_s3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the above script from a Lambda function, this will help us automoate this task later.\n",
    "\n",
    "First create the Lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "create_lambda_function(zip_name=\"codecommit_to_s3.zip\",\n",
    "                       lambda_source_code=\"./workflow-orchestration-src/codecommit_to_s3.py\",\n",
    "                       function_name=WORKFLOW_NAME + '-codecommit-to-s3',\n",
    "                       description=\"Copy code files from CodeCommit to a tarball on S3\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.invoke(\n",
    "    FunctionName=WORKFLOW_NAME + '-codecommit-to-s3',\n",
    "    Payload=json.dumps(my_workflow_input).encode()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\"SUCCESS\"'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"Payload\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-23 05:16:22       2894 codecommit_to_s3.zip\r\n",
      "2020-09-23 05:16:34       3778 create_sagemaker_prcoessing_job.zip\r\n",
      "2020-09-23 05:27:54       3211 create_sagemaker_training_job.zip\r\n",
      "2020-09-23 06:04:02       1493 processing.py\r\n",
      "2020-09-23 05:16:53       1010 query_data_processing_status.zip\r\n",
      "2020-09-23 05:28:07       1046 query_training_status.zip\r\n",
      "2020-09-23 06:04:01       1695 sourcedir.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {\"s3://{}/{}/source-code/\".format(BUCKET, WORKFLOW_DATE_TIME)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run SageMaker Processing Job with `boto3`\n",
    "\n",
    "The `boto3` client for SageMaker is more verbose than the SageMaker SDK yet gives more visibility in the low-level details of Amazon SageMaker.\n",
    "\n",
    "Let's look at the python script for our data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mwarnings\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[37m#from sklearn.model_selection import train_test_split\u001b[39;49;00m\r\n",
      "\u001b[37m#from sklearn.preprocessing import PowerTransformer, StandardScaler\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexceptions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataConversionWarning\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m gmtime, strftime\r\n",
      "\r\n",
      "warnings.filterwarnings(action=\u001b[33m'\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, category=DataConversionWarning)\r\n",
      "\r\n",
      "LOCAL_DATA_PATH = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train-test-split-ratio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.3\u001b[39;49;00m)\r\n",
      "    args, _ = parser.parse_known_args()\r\n",
      "    \r\n",
      "    split_ratio = args.train_test_split_ratio\r\n",
      "\r\n",
      "    input_data_path = os.path.join(LOCAL_DATA_PATH, \u001b[33m'\u001b[39;49;00m\u001b[33minput/boston.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mReading input data from \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(input_data_path))\r\n",
      "    df = pd.read_csv(input_data_path)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(df.shape)\r\n",
      "    \r\n",
      "    test_index = np.random.rand(\u001b[36mlen\u001b[39;49;00m(df)) < \u001b[34m0.2\u001b[39;49;00m\r\n",
      "    test_df = df[test_index].reset_index(drop=\u001b[34mTrue\u001b[39;49;00m)\r\n",
      "    df = df[~test_index].reset_index(drop=\u001b[34mTrue\u001b[39;49;00m)\r\n",
      "    valid_index = np.random.rand(\u001b[36mlen\u001b[39;49;00m(df)) < \u001b[34m0.2\u001b[39;49;00m\r\n",
      "    valid_df = df[valid_index].reset_index(drop=\u001b[34mTrue\u001b[39;49;00m)\r\n",
      "    train_df = df[~valid_index].reset_index(drop=\u001b[34mTrue\u001b[39;49;00m)\r\n",
      "\r\n",
      "\r\n",
      "    train_df.to_csv(os.path.join(LOCAL_DATA_PATH, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain/train.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), index = \u001b[34mFalse\u001b[39;49;00m)\r\n",
      "\r\n",
      "    valid_df.to_csv(os.path.join(LOCAL_DATA_PATH, \u001b[33m\"\u001b[39;49;00m\u001b[33mvalidation/validation.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), index = \u001b[34mFalse\u001b[39;49;00m)\r\n",
      "\r\n",
      "    test_df.to_csv(os.path.join(LOCAL_DATA_PATH, \u001b[33m\"\u001b[39;49;00m\u001b[33mtest/test.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), index = \u001b[34mFalse\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(train_df.shape)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(valid_df.shape)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(test_df.shape)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./sagemaker-processing-src/processing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the above script, we will use [boto3.client('sagemaker')\n",
    ".create_processing_job()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_processing_job) inside a lambda function.\n",
    "\n",
    "Here is the code for the lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\n",
      "sagemaker_boto3 = boto3.client(\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mlambda_handler\u001b[39;49;00m(event, context):\n",
      "    BUCKET = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mBUCKET\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    WORKFLOW_DATE_TIME = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORKFLOW_DATE_TIME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    JOB_NAME = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(event[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORKFLOW_NAME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], WORKFLOW_DATE_TIME)\n",
      "\n",
      "    DATA_SOURCE = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mDATA_SOURCE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    SOURCE_CODE_PREFIX = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/source-code\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(WORKFLOW_DATE_TIME)\n",
      "    PROCESSING_SCRIPT = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mPROCESSING_SCRIPT\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    \n",
      "    \u001b[37m# Output data paths\u001b[39;49;00m\n",
      "    TRAIN_PATH = \u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/data/train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(BUCKET, WORKFLOW_DATE_TIME)\n",
      "    VALID_PATH = \u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/data/validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(BUCKET, WORKFLOW_DATE_TIME)\n",
      "    TEST_PATH = \u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/data/test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(BUCKET, WORKFLOW_DATE_TIME)\n",
      "\n",
      "    response = sagemaker_boto3.create_processing_job(\n",
      "        ProcessingJobName = JOB_NAME,\n",
      "        ProcessingInputs = [\n",
      "            {\u001b[33m'\u001b[39;49;00m\u001b[33mInputName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33minput-1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "             \u001b[33m'\u001b[39;49;00m\u001b[33mS3Input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\u001b[33m'\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DATA_SOURCE,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mLocalPath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mS3Prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3InputMode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mFile\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataDistributionType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mShardedByS3Key\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3CompressionType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mNone\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                        }\n",
      "            },\n",
      "            {\u001b[33m'\u001b[39;49;00m\u001b[33mInputName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mcode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "             \u001b[33m'\u001b[39;49;00m\u001b[33mS3Input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\u001b[33m'\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(BUCKET, SOURCE_CODE_PREFIX, PROCESSING_SCRIPT),\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mLocalPath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/code\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mS3Prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3InputMode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mFile\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataDistributionType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mFullyReplicated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3CompressionType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mNone\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                        }\n",
      "            }\n",
      "        ],\n",
      "        ProcessingOutputConfig = {\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mOutputs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [{\u001b[33m'\u001b[39;49;00m\u001b[33mOutputName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3Output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\u001b[33m'\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TRAIN_PATH,\n",
      "                                      \u001b[33m'\u001b[39;49;00m\u001b[33mLocalPath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                      \u001b[33m'\u001b[39;49;00m\u001b[33mS3UploadMode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                                     }\n",
      "                        },\n",
      "                        {\u001b[33m'\u001b[39;49;00m\u001b[33mOutputName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mvalid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3Output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\u001b[33m'\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: VALID_PATH,\n",
      "                                      \u001b[33m'\u001b[39;49;00m\u001b[33mLocalPath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                      \u001b[33m'\u001b[39;49;00m\u001b[33mS3UploadMode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                                     }\n",
      "                        },\n",
      "                        {\u001b[33m'\u001b[39;49;00m\u001b[33mOutputName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mS3Output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\u001b[33m'\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TEST_PATH,\n",
      "                                      \u001b[33m'\u001b[39;49;00m\u001b[33mLocalPath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                      \u001b[33m'\u001b[39;49;00m\u001b[33mS3UploadMode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                                     }\n",
      "                        }]\n",
      "        },\n",
      "        ProcessingResources = {\u001b[33m'\u001b[39;49;00m\u001b[33mClusterConfig\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\u001b[33m'\u001b[39;49;00m\u001b[33mInstanceCount\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: event[\u001b[33m\"\u001b[39;49;00m\u001b[33mPROCESSING_INSTANCE_COUNT\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "                                                 \u001b[33m'\u001b[39;49;00m\u001b[33mInstanceType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: event[\u001b[33m\"\u001b[39;49;00m\u001b[33mPROCESSING_INSTANCE_TYPE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "                                                 \u001b[33m'\u001b[39;49;00m\u001b[33mVolumeSizeInGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: event[\u001b[33m\"\u001b[39;49;00m\u001b[33mPROCESSING_VOLUME_SIZE_GB\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "                                                }\n",
      "                              },\n",
      "        StoppingCondition = {\u001b[33m'\u001b[39;49;00m\u001b[33mMaxRuntimeInSeconds\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34m86400\u001b[39;49;00m},\n",
      "        AppSpecification = {\u001b[33m'\u001b[39;49;00m\u001b[33mImageUri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: event[\u001b[33m\"\u001b[39;49;00m\u001b[33mPROCESSING_IMAGE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mContainerArguments\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:  [\u001b[33m'\u001b[39;49;00m\u001b[33m--train-test-split-ratio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m0.2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mContainerEntrypoint\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mpython3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \n",
      "                                                    \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/code/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m+ event[\u001b[33m\"\u001b[39;49;00m\u001b[33mPROCESSING_SCRIPT\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "                                                   ]\n",
      "                           },\n",
      "        RoleArn = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mROLE_ARN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    )\n",
      "    \u001b[34mreturn\u001b[39;49;00m event\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./workflow-orchestration-src/create_sagemaker_prcoessing_job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "create_lambda_function(zip_name=\"create_sagemaker_prcoessing_job.zip\",\n",
    "                       lambda_source_code=\"./workflow-orchestration-src/create_sagemaker_prcoessing_job.py\",\n",
    "                       function_name=WORKFLOW_NAME + '-create-sagemaker-prcoessing-job',\n",
    "                       description=\"Creates Sagemaker Processing Job\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.invoke(\n",
    "    FunctionName=WORKFLOW_NAME + '-create-sagemaker-prcoessing-job',\n",
    "    Payload=json.dumps(my_workflow_input).encode()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"REGION\": \"us-east-1\", \"ROLE_ARN\": \"arn:aws:iam::227921966468:role/My-StepFunction-Workflow-Role\", \"BUCKET\": \"my-project-227921966468\", \"WORKFLOW_NAME\": \"my-project-2\", \"WORKFLOW_DATE_TIME\": \"2020-09-23-05-16-18\", \"DATA_SOURCE\": \"s3://my-datalake-227921966468/data/boston.csv\", \"REPO\": \"my-project\", \"BRANCH\": \"master\", \"DATA_PROCESSING_DIR\": \"sagemaker-processing-src\", \"ML_DIR\": \"sagemaker-train-serve-src\", \"PROCESSING_SCRIPT\": \"processing.py\", \"PROCESSING_IMAGE\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\", \"PROCESSING_INSTANCE_TYPE\": \"ml.c5.xlarge\", \"PROCESSING_INSTANCE_COUNT\": 1, \"PROCESSING_VOLUME_SIZE_GB\": 10, \"TRAINING_SCRIPT\": \"train.py\", \"TRAINING_IMAGE\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\", \"TRAINING_INSTANCE_TYPE\": \"ml.c5.xlarge\", \"TRAINING_INSTANCE_COUNT\": 1, \"TRAINING_VOLUME_SIZE_GB\": 10, \"SERVING_SCRIPT\": \"serve.py\", \"SERVING_IMAGE\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\", \"SERVING_INSTANCE_TYPE\": \"ml.c5.xlarge\", \"SERVING_INSTANCE_COUNT\": 1, \"SERVING_VOLUME_SIZE_GB\": 10}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"Payload\"].read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a mechanism to check on the processing job status... again using a Lambda!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "create_lambda_function(zip_name='query_data_processing_status.zip',\n",
    "                       lambda_source_code='./workflow-orchestration-src/query_data_processing_status.py',\n",
    "                       function_name=WORKFLOW_NAME + '-query-data-processing-status',\n",
    "                       description='Get Status of SageMaker Processing Job'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure the SageMaker processing job is done (status = Completed) before luanching the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/my-github-repos/eventengine/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions/workflow-orchestration-src\n",
      "{'statusCode': 200, 'ProcessingJobStatus': 'Completed'}\n",
      "/home/ec2-user/SageMaker/my-github-repos/eventengine/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions\n"
     ]
    }
   ],
   "source": [
    "%cd ./workflow-orchestration-src\n",
    "import query_data_processing_status as qs\n",
    "print(qs.lambda_handler(my_workflow_input, \"\"))\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE data/\r\n",
      "                           PRE source-code/\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {\"s3://{}/{}/\".format(BUCKET, WORKFLOW_DATE_TIME)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create SageMaker Training Job Using `boto3`\n",
    "\n",
    "When using `boto3` to launch a training job, we must explicitly point it to our source code on S3 and docker image in addition to what SageMaker estimators expect.\n",
    "\n",
    "Let's look at the code for the `create_sagemaker_training_job` lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "sagemaker_boto3 = boto3.client(\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mlambda_handler\u001b[39;49;00m(event, context):\n",
      "    \u001b[33m\"\"\" Creates a SageMaker training job\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    BUCKET = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mBUCKET\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    WORKFLOW_DATE_TIME = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORKFLOW_DATE_TIME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    PREFIX = \u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(BUCKET, WORKFLOW_DATE_TIME)\n",
      "\n",
      "    TRAINING_DATA = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/data/train/train.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(PREFIX)\n",
      "    VALIDATION_DATA = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/data/validation/validation.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(PREFIX)\n",
      "    SOURCE_CODE = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(PREFIX, \u001b[33m\"\u001b[39;49;00m\u001b[33msource-code/sourcedir.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    ENTRY_POINT_SCRIPT = event[\u001b[33m'\u001b[39;49;00m\u001b[33mTRAINING_SCRIPT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    TRAINING_IMAGE = event[\u001b[33m'\u001b[39;49;00m\u001b[33mTRAINING_IMAGE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    ROLE_ARN = event[\u001b[33m'\u001b[39;49;00m\u001b[33mROLE_ARN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    OUTPUT_ARTIFACTS_PATH = \u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(BUCKET, WORKFLOW_DATE_TIME + \u001b[33m'\u001b[39;49;00m\u001b[33m/model-artifacts/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    INSTANCE_TYPE = event[\u001b[33m'\u001b[39;49;00m\u001b[33mTRAINING_INSTANCE_TYPE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    INSTANCE_COUNT = event[\u001b[33m'\u001b[39;49;00m\u001b[33mTRAINING_INSTANCE_COUNT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    VOLUME_SIZE_GB = event[\u001b[33m'\u001b[39;49;00m\u001b[33mTRAINING_VOLUME_SIZE_GB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    \n",
      "    WORKFLOW_NAME = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORKFLOW_NAME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    TRAINING_JOB_NAME = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(WORKFLOW_NAME, WORKFLOW_DATE_TIME)\n",
      "\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        response = sagemaker_boto3.create_training_job(\n",
      "            TrainingJobName=TRAINING_JOB_NAME,\n",
      "            HyperParameters={\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mn_estimators\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m300\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mmin_samples_leaf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33msagemaker_program\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: ENTRY_POINT_SCRIPT,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33msagemaker_submit_directory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: SOURCE_CODE      \n",
      "            },\n",
      "            AlgorithmSpecification={\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mTrainingImage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TRAINING_IMAGE,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mTrainingInputMode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mFile\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mMetricDefinitions\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\n",
      "                    {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mmedian-APE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mAPE-at-50th-percentile: ([0-9.]+).*$\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\n",
      "                ]\n",
      "            },\n",
      "            RoleArn=ROLE_ARN,\n",
      "            InputDataConfig=[\n",
      "                {\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mChannelName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mDataSource\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataSource\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mS3Prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TRAINING_DATA,\n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataDistributionType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mFullyReplicated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mChannelName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mDataSource\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataSource\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mS3Prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: VALIDATION_DATA,\n",
      "                            \u001b[33m'\u001b[39;49;00m\u001b[33mS3DataDistributionType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mFullyReplicated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "            ],\n",
      "            OutputDataConfig={\u001b[33m'\u001b[39;49;00m\u001b[33mS3OutputPath\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: OUTPUT_ARTIFACTS_PATH},\n",
      "            ResourceConfig={\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mInstanceType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: INSTANCE_TYPE,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mInstanceCount\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: INSTANCE_COUNT,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mVolumeSizeInGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: VOLUME_SIZE_GB\n",
      "            },\n",
      "            StoppingCondition={\u001b[33m'\u001b[39;49;00m\u001b[33mMaxRuntimeInSeconds\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34m86400\u001b[39;49;00m},\n",
      "            EnableNetworkIsolation=\u001b[34mFalse\u001b[39;49;00m\n",
      "        )\n",
      "        \u001b[36mprint\u001b[39;49;00m(response)\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to create model.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        \u001b[34mraise\u001b[39;49;00m(e)\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m response\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./workflow-orchestration-src/create_sagemaker_training_job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "create_lambda_function(zip_name='create_sagemaker_training_job.zip',\n",
    "                       lambda_source_code='./workflow-orchestration-src/create_sagemaker_training_job.py',\n",
    "                       function_name=WORKFLOW_NAME + '-create-sagemaker-training-job',\n",
    "                       description='Creates SageMaker Training Job'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training job once processing job is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.invoke(\n",
    "    FunctionName=WORKFLOW_NAME + '-create-sagemaker-training-job',\n",
    "    Payload=json.dumps(my_workflow_input).encode()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"TrainingJobArn\": \"arn:aws:sagemaker:us-east-1:227921966468:training-job/my-project-2-2020-09-23-05-16-18\", \"ResponseMetadata\": {\"RequestId\": \"d3bc01c5-791b-475b-aa54-1304914ceb0e\", \"HTTPStatusCode\": 200, \"HTTPHeaders\": {\"x-amzn-requestid\": \"d3bc01c5-791b-475b-aa54-1304914ceb0e\", \"content-type\": \"application/x-amz-json-1.1\", \"content-length\": \"107\", \"date\": \"Wed, 23 Sep 2020 05:27:57 GMT\"}, \"RetryAttempts\": 0}}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"Payload\"].read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check on its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "create_lambda_function(zip_name='query_training_status.zip',\n",
    "                       lambda_source_code='./workflow-orchestration-src/query_training_status.py',\n",
    "                       function_name=WORKFLOW_NAME + '-query-training-status',\n",
    "                       description='Get Status of SageMaker Training Job'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure the SageMaker training job is done (status = Completed) before deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/my-github-repos/eventengine/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions/workflow-orchestration-src\n",
      "{'statusCode': 200, 'TrainingJobStatus': 'Failed'}\n",
      "/home/ec2-user/SageMaker/my-github-repos/eventengine/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions\n"
     ]
    }
   ],
   "source": [
    "%cd ./workflow-orchestration-src\n",
    "import query_training_status as qs\n",
    "print(qs.lambda_handler(my_workflow_input, \"\"))\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE data/\r\n",
      "                           PRE source-code/\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {\"s3://{}/{}/\".format(BUCKET, WORKFLOW_DATE_TIME)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Deploy model on SageMaker using model artifacts on S3 using `boto3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If training is done, then check model accuracy before deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "create_lambda_function(zip_name='query_model_accuracy.zip',\n",
    "                       lambda_source_code='./workflow-orchestration-src/query_model_accuracy.py',\n",
    "                       function_name=WORKFLOW_NAME + '-query-model-accuracy',\n",
    "                       description='Get Model Accuracy from SageMaker Training Job'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/my-github-repos/eventengine/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions/workflow-orchestration-src\n",
      "{'statusCode': 200, 'trainingMetrics': []}\n",
      "/home/ec2-user/SageMaker/my-github-repos/eventengine/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions\n"
     ]
    }
   ],
   "source": [
    "%cd ./workflow-orchestration-src\n",
    "import query_model_accuracy as qs\n",
    "print(qs.lambda_handler(my_workflow_input, \"\"))\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the code for the `deploy_sagemaker_model` lambda function. This function will be incharge of creating a SageMaker endpoint for our trained model. If endpoint exists, then it will update the endpoint with the new retrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\r\n",
      "sagemaker_boto3 = boto3.client(\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mlambda_handler\u001b[39;49;00m(event, context):\r\n",
      "    \u001b[33m\"\"\" Creates a SageMaker model and either\u001b[39;49;00m\r\n",
      "\u001b[33m    updates or creates an endpoint\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    BUCKET = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mBUCKET\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "    WORKFLOW_NAME = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORKFLOW_NAME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "    WORKFLOW_DATE_TIME = event[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORKFLOW_DATE_TIME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "\r\n",
      "    prefix = \u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(BUCKET, WORKFLOW_DATE_TIME)\r\n",
      "    name = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(WORKFLOW_NAME, WORKFLOW_DATE_TIME)\r\n",
      "    endpoint = WORKFLOW_NAME\r\n",
      "    container = event[\u001b[33m'\u001b[39;49;00m\u001b[33mSERVING_IMAGE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    \r\n",
      "            \r\n",
      "    \u001b[37m#model_prefix = \"{}/{}\".format(prefix, \"model-artifacts\")\u001b[39;49;00m\r\n",
      "    \u001b[37m#model_suffix = \"{}-{}/{}\".format(WORKFLOW_NAME, WORKFLOW_DATE_TIME, \"output/model.tar.gz\")\u001b[39;49;00m\r\n",
      "    \u001b[37m#model_data_url = \"{}/{}\".format(model_prefix, model_suffix)\u001b[39;49;00m\r\n",
      "\r\n",
      "    model_data_url = sagemaker_boto3.describe_training_job(TrainingJobName=name)[\u001b[33m'\u001b[39;49;00m\u001b[33mModelArtifacts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mS3ModelArtifacts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "    \r\n",
      "    event[\u001b[33m\"\u001b[39;49;00m\u001b[33mSOURCE_CODE_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(prefix, \u001b[33m\"\u001b[39;49;00m\u001b[33msource-code/sourcedir.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mCreating model resource from training artifact...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    create_model(name, container, model_data_url, event)\r\n",
      "    \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mCreating endpoint configuration...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    create_endpoint_config(name, event)\r\n",
      "    \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mChecking if model endpoint already exists...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mif\u001b[39;49;00m check_endpoint_exists(endpoint):\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mExisting endpoint found for model. Updating existing model endpoint...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        update_endpoint(endpoint, name)\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mThere is no existing endpoint for this model. Creating new model endpoint...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        create_endpoint(endpoint, name)\r\n",
      "    event[\u001b[33m'\u001b[39;49;00m\u001b[33mstage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33mDeployment\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    event[\u001b[33m'\u001b[39;49;00m\u001b[33mstatus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33mCreating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    event[\u001b[33m'\u001b[39;49;00m\u001b[33mmessage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33mStarted deploying model \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m to endpoint \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(name, endpoint)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m event\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_model\u001b[39;49;00m(name, container, model_data_url, env_params):\r\n",
      "    \u001b[33m\"\"\" Create SageMaker model.\u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m        name (string): Name to label model with\u001b[39;49;00m\r\n",
      "\u001b[33m        container (string): Registry path of the Docker image that contains the model algorithm\u001b[39;49;00m\r\n",
      "\u001b[33m        model_data_url (string): URL of the model artifacts created during training to download to container\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m        (None)\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        sagemaker_boto3.create_model(\r\n",
      "            ModelName=name,\r\n",
      "            PrimaryContainer={\r\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mImage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: container,\r\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mModelDataUrl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model_data_url,\r\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mEnvironment\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:{\r\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_CONTAINER_LOG_LEVEL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33m20\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_PROGRAM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: env_params[\u001b[33m'\u001b[39;49;00m\u001b[33mSERVING_SCRIPT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_SUBMIT_DIRECTORY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: env_params[\u001b[33m'\u001b[39;49;00m\u001b[33mSOURCE_CODE_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_REGION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: env_params[\u001b[33m'\u001b[39;49;00m\u001b[33mREGION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_ENABLE_CLOUDWATCH_METRICS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mfalse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "                }\r\n",
      "            },\r\n",
      "            ExecutionRoleArn=env_params[\u001b[33m'\u001b[39;49;00m\u001b[33mROLE_ARN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "        )\r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to create model.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[34mraise\u001b[39;49;00m(e)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_endpoint_config\u001b[39;49;00m(name, env_params):\r\n",
      "    \u001b[33m\"\"\" Create SageMaker endpoint configuration. \u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m        name (string): Name to label endpoint configuration with.\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m        (None)\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        sagemaker_boto3.create_endpoint_config(\r\n",
      "            EndpointConfigName=name,\r\n",
      "            ProductionVariants=[\r\n",
      "                {\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mVariantName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mAllTraffic\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                    \r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mModelName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: name,\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mInitialInstanceCount\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: env_params[\u001b[33m'\u001b[39;49;00m\u001b[33mSERVING_INSTANCE_COUNT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mInstanceType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: env_params[\u001b[33m'\u001b[39;49;00m\u001b[33mSERVING_INSTANCE_TYPE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "                }\r\n",
      "            ]\r\n",
      "        )\r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to create endpoint configuration.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[34mraise\u001b[39;49;00m(e)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcheck_endpoint_exists\u001b[39;49;00m(endpoint_name):\r\n",
      "    \u001b[33m\"\"\" Check if SageMaker endpoint for model already exists.\u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m        endpoint_name (string): Name of endpoint to check if exists.\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m        (boolean)\u001b[39;49;00m\r\n",
      "\u001b[33m        True if endpoint already exists.\u001b[39;49;00m\r\n",
      "\u001b[33m        False otherwise.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        sagemaker_boto3.describe_endpoint(\r\n",
      "            EndpointName=endpoint_name\r\n",
      "        )\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34mTrue\u001b[39;49;00m\r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34mFalse\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_endpoint\u001b[39;49;00m(endpoint_name, config_name):\r\n",
      "    \u001b[33m\"\"\" Create SageMaker endpoint with input endpoint configuration.\u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m        endpoint_name (string): Name of endpoint to create.\u001b[39;49;00m\r\n",
      "\u001b[33m        config_name (string): Name of endpoint configuration to create endpoint with.\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m        (None)\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        sagemaker_boto3.create_endpoint(\r\n",
      "            EndpointName=endpoint_name,\r\n",
      "            EndpointConfigName=config_name\r\n",
      "        )\r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to create endpoint.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[34mraise\u001b[39;49;00m(e)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mupdate_endpoint\u001b[39;49;00m(endpoint_name, config_name):\r\n",
      "    \u001b[33m\"\"\" Update SageMaker endpoint to input endpoint configuration. \u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m        endpoint_name (string): Name of endpoint to update.\u001b[39;49;00m\r\n",
      "\u001b[33m        config_name (string): Name of endpoint configuration to update endpoint with.\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m        (None)\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        sagemaker_boto3.update_endpoint(\r\n",
      "            EndpointName=endpoint_name,\r\n",
      "            EndpointConfigName=config_name\r\n",
      "        )\r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to update endpoint.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[34mraise\u001b[39;49;00m(e)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./workflow-orchestration-src/deploy_sagemaker_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's put this function in a Lambda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "create_lambda_function(zip_name='deploy_sagemaker_model.zip',\n",
    "                       lambda_source_code='./workflow-orchestration-src/deploy_sagemaker_model.py',\n",
    "                       function_name=WORKFLOW_NAME + '-deploy-sagemaker-model-job',\n",
    "                       description='Creates and Deploys SageMaker Model From Training Artifacts'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.invoke(\n",
    "    FunctionName=WORKFLOW_NAME + '-deploy-sagemaker-model-job',\n",
    "    Payload=json.dumps(my_workflow_input).encode()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"errorMessage\": \"An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3://my-project-227921966468/2020-09-23-05-16-18/model-artifacts/my-project-2-2020-09-23-05-16-18/output/model.tar.gz.\", \"errorType\": \"ClientError\", \"stackTrace\": [[\"/var/task/deploy_sagemaker_model.py\", 31, \"lambda_handler\", \"create_model(name, container, model_data_url, event)\"], [\"/var/task/deploy_sagemaker_model.py\", 78, \"create_model\", \"raise(e)\"], [\"/var/task/deploy_sagemaker_model.py\", 73, \"create_model\", \"ExecutionRoleArn=env_params[\\'ROLE_ARN\\']\"], [\"/var/runtime/botocore/client.py\", 316, \"_api_call\", \"return self._make_api_call(operation_name, kwargs)\"], [\"/var/runtime/botocore/client.py\", 635, \"_make_api_call\", \"raise error_class(parsed_response, operation_name)\"]]}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"Payload\"].read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from six import BytesIO\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Extract Enviroment Vars\n",
    "ENDPOINT_NAME = \"octank\"\n",
    "PROD_FEATURES_TABLE_NAME = \"octank-prod-features\"\n",
    "\n",
    "# Set up DynamoDB and SageMaker clients\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "prod_features_table = dynamodb.Table(PROD_FEATURES_TABLE_NAME)\n",
    "\n",
    "\n",
    "# Fetch features from DynamoDB\n",
    "payload = prod_features_table.get_item(\n",
    "    Key={'tconst': \"tt1064899\",\n",
    "         'season': 1\n",
    "        }\n",
    ")[\"Item\"]\n",
    "\n",
    "# JSON serialize the features vector\n",
    "converted_payload = {key:str(value) for (key,value) in payload.items()}\n",
    "serialized_payload = json.dumps(converted_payload).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/octank in account 227921966468 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bc54e7142263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m response = sagemaker_runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n\u001b[1;32m      3\u001b[0m                                              \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserialized_payload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                              \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'application/json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                                             )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/octank in account 227921966468 for more information."
     ]
    }
   ],
   "source": [
    "# Invoke SageMaker endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                             Body=serialized_payload,\n",
    "                                             ContentType='application/json'\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00026849]\n"
     ]
    }
   ],
   "source": [
    "# Endpoint sends serialized numpy array, let's unpack\n",
    "stream = BytesIO(response['Body'].read())\n",
    "prediction = np.load(stream, allow_pickle=True)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
