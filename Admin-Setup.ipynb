{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admin Setup\n",
    "In this notebook we play the role of Data and DevOps engineers who are in charge of maintaining S3 resources (datalake and project buckets) as well as the code repository, Docker image for model training/hosting and IAM credentials respectively.\n",
    "\n",
    "**This sample is provided for demonstration purposes, make sure to conduct appropriate testing if derivating this code for your own use-cases!**\n",
    "\n",
    "\n",
    "### Step 1: Create CodeCommit Repo and Push Code to it\n",
    "The cell below creates an AWS CodeCommit repo for this demo. It then adds, commits and pushs our code to this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_session.region_name\n",
    "\n",
    "codecommit_client = boto3.client('codecommit')\n",
    "\n",
    "repo_name = \"my-project\"\n",
    "repo_desc = \"Automated model (re)training and endpoint upadates via AWS Lambda and Step Functions\"\n",
    "\n",
    "\n",
    "response = codecommit_client.create_repository(\n",
    "    repositoryName=repo_name,\n",
    "    repositoryDescription=repo_desc,\n",
    "    tags={\n",
    "        'author': \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "%cd /home/ec2-user/SageMaker/\n",
    "!git clone https://git-codecommit.us-east-1.amazonaws.com/v1/repos/{repo_name} /home/ec2-user/SageMaker/{repo_name}\n",
    "    \n",
    "!cp -r /home/ec2-user/SageMaker/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions/* /home/ec2-user/SageMaker/{repo_name}/\n",
    "\n",
    "%cd /home/ec2-user/SageMaker/{repo_name}/\n",
    "!git add .\n",
    "!git commit -m \"...\"\n",
    "\n",
    "!git push\n",
    "\n",
    "%cd /home/ec2-user/SageMaker/serverless-mlops-with-aws-sagemaker-lambda-and-stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a toy \"datalake\" S3 and a \"my-project\" bucket\n",
    "The following cell creates two S3 buckets `my-datalake` and `my-project`, feel free to choose whatever name you like. It then:\n",
    "* Uploads our labeled but pre-processed dataset to the `my-datalake` bucket... we will not mess with this bucket, it's job of a data engineer to maintaine it.\n",
    "* We however will work with the `my-project` bucket. We will store everything in it, from our processed datasets to our source code, model binaries and model performance statitics, all of which will be versioned with respect to the date at which the workfolow was launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    \"\"\"Create an S3 bucket in a specified region\n",
    "\n",
    "    If a region is not specified, the bucket is created in the S3 default\n",
    "    region (us-east-1).\n",
    "\n",
    "    :param bucket_name: Bucket to create\n",
    "    :param region: String region to create bucket in, e.g., 'us-west-2'\n",
    "    :return: True if bucket created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bucket\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3_client = boto3.client('s3', region_name=region)\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Create S3 Buckets for this project (pass if they exist)\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "source_bucket = \"my-datalake-{account_id}\".format(account_id=account_id)\n",
    "project_bucket = \"my-project-{account_id}\".format(account_id=account_id)\n",
    "\n",
    "create_bucket(bucket_name=source_bucket, region=None)\n",
    "create_bucket(bucket_name=project_bucket, region=None)\n",
    "print(\"*****************************Storage*******************************\")\n",
    "print(\"Source Bucket: {bucket}\".format(bucket=source_bucket))\n",
    "print(\"Project Bucket: {bucket}\".format(bucket=project_bucket))\n",
    "\n",
    "# Upload toy data to the source-bucket \"datalake\". Here we use the Boston house prices dataset\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['PRICE'] = data.target\n",
    "df.to_csv(\"boston.csv\", index=None)\n",
    "data_source = S3Uploader.upload(local_path='boston.csv',\n",
    "                               desired_s3_uri=\"s3://{}/{}\".format(source_bucket, \"data\"),\n",
    "                               session=session\n",
    "                               )\n",
    "print(\"Source Dataset: {} \\n\".format(data_source))\n",
    "\n",
    "admin_setup = {\n",
    "    \"source_bucket\":source_bucket,\n",
    "    \"raw_data_path\":data_source,\n",
    "    \"project_bucket\":project_bucket,\n",
    "    \"repo_name\":repo_name\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Docker image for model training/hosting\n",
    "\n",
    "We have to create a Docker Image for our training container and submit it to Amazon ECR. In this demo, we will use the pre-built [sagemaker-scikit-learn](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-docker-containers-frameworks.html) image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Docker Image for Training Job\n",
    "def container_arn(region):\n",
    "    image_registry_map = {\n",
    "        'us-west-1': '746614075791',\n",
    "        'us-west-2': '246618743249',\n",
    "        'us-east-1': '683313688378',\n",
    "        'us-east-2': '257758044811',\n",
    "        'ap-northeast-1': '354813040037',\n",
    "        'ap-northeast-2': '366743142698',\n",
    "        'ap-southeast-1': '121021644041',\n",
    "        'ap-southeast-2': '783357654285',\n",
    "        'ap-south-1': '720646828776',\n",
    "        'eu-west-1': '141502667606',\n",
    "        'eu-west-2': '764974769150',\n",
    "        'eu-central-1': '492215442770',\n",
    "        'ca-central-1': '341280168497',\n",
    "        'us-gov-west-1': '414596584902',\n",
    "        'us-iso-east-1': '833128469047',\n",
    "    }\n",
    "    return (image_registry_map[region] + '.dkr.ecr.' + region \n",
    "            + '.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3')\n",
    "\n",
    "print(\"**************************Training Image***************************\")\n",
    "print(\"Docker Training Image: {} \\n\".format(container_arn(region)))\n",
    "\n",
    "admin_setup[\"docker_image\"] = container_arn(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create IAM Policies and Roles\n",
    "We'll finally create an IAM role for our workflow. The IAM roles grant the services permissions within your AWS environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IAM Policies and Roles for this project (pass if they exist)\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "# Get Policy ARN in order to attach it to role later\n",
    "aws_managed_basic_lambda_policy_ARN = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n",
    "aws_managed_lambda_policy_ARN = \"arn:aws:iam::aws:policy/service-role/AWSLambdaRole\"\n",
    "aws_managed_step_functions_policy_ARN = \"arn:aws:iam::aws:policy/AWSStepFunctionsFullAccess\"\n",
    "aws_managed_sagemaker_policy_ARN = \"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\"\n",
    "aws_managed_s3_policy_ARN = \"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
    "aws_managed_codecommit_policy_ARN = \"arn:aws:iam::aws:policy/AWSCodeCommitFullAccess\"\n",
    "\n",
    "\n",
    "# Set Role/Policy names\n",
    "step_function_role_name = \"My-StepFunction-Workflow-Role\"\n",
    "step_function_role_description = \"Role to allow a step function systematic access to invoke Lambda functions, run data processing jobs in Glue, run SageMaker training jobs and update endpoints\"\n",
    "\n",
    "step_function_trust_policy = {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Sid\": \"\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"states.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    },\n",
    "    {\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Principal\": {\n",
    "            \"Service\": \"sagemaker.amazonaws.com\"\n",
    "        },\n",
    "        \"Action\": \"sts:AssumeRole\"\n",
    "    },\n",
    "    {\n",
    "      \"Sid\": \"\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"lambda.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Create Step Function Role (pass if it already exists)\n",
    "try:\n",
    "    step_function_role = iam.create_role(\n",
    "        RoleName=step_function_role_name,\n",
    "        Description=step_function_role_description,\n",
    "        AssumeRolePolicyDocument=json.dumps(step_function_trust_policy),\n",
    "        MaxSessionDuration=3600\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Unable to create {}\".format(step_function_role_name))\n",
    "\n",
    "    \n",
    "# Attach the SageMaker Full Access Policy\n",
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        PolicyArn=aws_managed_sagemaker_policy_ARN,\n",
    "        RoleName=step_function_role_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Unable to attach {} to {}\".format(aws_managed_sagemaker_policy_ARN, step_function_role_name))\n",
    "\n",
    "# Attach Step Function Full Access Policy to Role (pass if it already exists)\n",
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        PolicyArn=aws_managed_step_functions_policy_ARN,\n",
    "        RoleName=step_function_role_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Unable to attach {} to {}\".format(aws_managed_step_functions_policy_ARN, step_function_role_name))\n",
    "\n",
    "\n",
    "# Attach the Lambda policies\n",
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        PolicyArn=aws_managed_lambda_policy_ARN,\n",
    "        RoleName=step_function_role_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Unable to attach {} to {}\".format(aws_managed_lambda_policy_ARN, step_function_role_name))\n",
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        PolicyArn=aws_managed_basic_lambda_policy_ARN,\n",
    "        RoleName=step_function_role_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Unable to attach {} to {}\".format(aws_managed_basic_lambda_policy_ARN, step_function_role_name))\n",
    "\n",
    "# S3\n",
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        PolicyArn=aws_managed_s3_policy_ARN,\n",
    "        RoleName=step_function_role_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Unable to attach {} to {}\".format(aws_managed_s3_policy_ARN, step_function_role_name))\n",
    "\n",
    "# CodeCommit\n",
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        PolicyArn=aws_managed_codecommit_policy_ARN,\n",
    "        RoleName=step_function_role_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Unable to attach {} to {}\".format(aws_managed_codecommit_policy_ARN, step_function_role_name))\n",
    "\n",
    "# Get Role ARN in order to print\n",
    "step_function_role_ARN = \"arn:aws:iam::{account}:role/{name}\".format(account=account_id, name=step_function_role_name)\n",
    "print(\"Step Function Role ARN: {arn}\".format(arn = step_function_role_ARN))\n",
    "\n",
    "admin_setup[\"workflow_execution_role\"] = step_function_role_ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('admin_setup.txt', 'w') as filehandle:\n",
    "    filehandle.write(json.dumps(admin_setup))\n",
    "    \n",
    "admin_setup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
